{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNiUhlIlhsBFVdJ4gnbodO/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hpTfOZsxS13R","executionInfo":{"status":"ok","timestamp":1672074829425,"user_tz":-345,"elapsed":3624,"user":{"displayName":"Pralhad Adhikari","userId":"08036984963191132985"}},"outputId":"70dc0ddb-53d6-4ff5-979c-8c8d4891cf12","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"w9YqZvD5UAQn","outputId":"2b7232a5-b199-4045-b779-f80659818ce9","colab":{"base_uri":"https://localhost:8080/"}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","import seaborn as sns\n","from sklearn.datasets import load_files\n","from pathlib import Path\n","from keras.models import Sequential\n","from keras.layers import Embedding,Dropout,LSTM,Flatten,Conv1D,GlobalMaxPooling1D,MaxPooling1D\n","import keras\n","import nltk\n","nltk.download('stopwords')\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing import sequence\n","from nltk.corpus import stopwords\n","stop_words=stopwords.words('nepali')\n","from nltk.tokenize import word_tokenize\n","import matplotlib.pyplot as plt\n","\n","data= pd.read_csv('/content/drive/My Drive/Colab Notebooks/updatedop.csv',encoding='utf8')\n","\n","print('Total data=',int(len(data)))\n","print((data['category'].value_counts()))\n","\n","seed=7\n","X=data.news\n","Y=data.category\n","\n","#exit(0)\n","le = LabelEncoder()\n","Y = le.fit_transform(Y)\n","\n","print(Y)\n","\n","\n","Y = Y.reshape(-1,1)\n","\n","train_size = int(len(data) * .8)\n","print (\"Train size: %d\" % train_size)\n","print (\"Test size: %d\" % (len(data) - train_size))\n","\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","cvscores = []\n","for train, test in kfold.split(X, Y):\n","    X_train=X[train]\n","    X_test=X[test]\n","    Y_train=Y[train]\n","    Y_test=Y[test]\n","\n","    max_words = 60000\n","    max_len = 300\n","    tok = Tokenizer(num_words=max_words)\n","    tok.fit_on_texts(X_train)\n","    sequences = tok.texts_to_sequences(X_train)\n","    sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n","    print('Shape of data tensor:', sequences_matrix.shape)\n","\n","#exit(0)\n","    model = Sequential()\n","    print('Build model...')\n","    model.add(Embedding(max_words,64,input_length=max_len))\n","\n","    model.add(LSTM(300,return_sequences=True))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Conv1D(300, 5,padding='valid',\n","                 activation='relu',\n","                 strides=1))\n","\n","    model.add(Dropout(0.5))\n","\n","    model.add(Conv1D(300, 3,padding='valid',\n","                   activation='relu',\n","                   strides=1))\n","#model.add(Dropout(0.5))\n","    model.add(GlobalMaxPooling1D())\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(9))\n","    model.add(Activation('softmax'))\n","\n","\n","    model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])\n","\n","#model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,validation_split=0.2)\n","\n","\n","    test_sequences = tok.texts_to_sequences(X_test)\n","    test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n","\n","#exit(0)\n","\n","    history = model.fit(sequences_matrix,Y_train,\n","                    batch_size=64,\n","                    epochs=10\n","                    )\n","\n","\n","\n","    scores = model.evaluate(test_sequences_matrix,Y_test,\n","                            batch_size=64)                           \n","\n","#accr = model.evaluate(sequences_matrix,X_train)\n","#print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n","\n","    print('Test loss:', scores[0])\n","    print('Test accuracy:', scores[1])\n","    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","    cvscores.append(scores[1] * 100)\n","\n","\n","\n","exit(0)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Total data= 99641\n","sports           20805\n","economy          17579\n","international    16267\n","entertainment    12027\n","politics         10287\n","diaspora          8382\n","health            7337\n","technology        6957\n","Name: category, dtype: int64\n","[6 6 5 ... 3 3 5]\n","Train size: 79712\n","Test size: 19929\n"]}]}]}